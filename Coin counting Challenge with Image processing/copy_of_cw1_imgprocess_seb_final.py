# -*- coding: utf-8 -*-
"""Copy of CW1_ImgProcess_Seb_FINAL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MV0S6e6vgdHzeVVaSYs2OejHdFcmeudm

# **Counting Coins challenge for Course work 1 of Image processing and Machine Vision**

The first step is to upload the test images for processing.
"""

from google.colab import files
uploaded = files.upload()

"""Open all of  the uploaded images and convert them to HSV. Store all the colour channel values into an array of 3 matrices, which are then stored in img_HSV[i]"""

#To HSV
import cv2
img_HSV=[] #array (list) of HSV images
filename=[] #array (list) of file names
i=0
for fn in uploaded.keys(): #for each filename
  filename.append(fn) #append to filenames array
  #open the uploaded image file and convert from BGR to HSV
  hsv = cv2.cvtColor(cv2.imread(filename[i]), cv2.COLOR_BGR2HSV)
  #hsv is single image with 3 channels (H, S, V)
  img_HSV.append(cv2.split(hsv))  #split to array of 3 images, add to HSV array
  i = i + 1
print('Converted '+str( len(img_HSV) )+' images')
Vdim = hsv.shape[0] #rows
Hdim = hsv.shape[1] #cols
print('Hdim: ' + str(Hdim) + '; Vdim: ' + str(Vdim))



"""Threshold value to get objects as foreground into a binary image."""

import cv2 # Import the OpenCV library with the alias cv2
import numpy as np
from google.colab.patches import cv2_imshow # Import cv2_imshow for displaying images in Colab

import pandas as pd
from google.colab import files
import matplotlib.pyplot as plt


# Assuming 'image_to_use' and 'filename' are defined from previous cells
image_to_use = 0  # Replace with the index of the image you want to use
# Load the source image using cv2.imread
src = cv2.imread(filename[image_to_use])

# Show source image
cv2_imshow(src) # Use cv2_imshow instead of cv2.imshow, pass only the image
src[np.all(src == 255, axis=2)] = 0
# Show output image
cv2_imshow(src) # Use cv2_imshow instead of cv2.imshow, pass only the image

# Replace all instances of cv2.imshow with cv2_imshow in the rest of your code

kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)
# do the laplacian filtering as it is
# well, we need to convert everything in something more deeper then CV_8U
# because the kernel has some negative values,
# and we can expect in general to have a Laplacian image with negative values
# BUT a 8bits unsigned int (the one we are working with) can contain values from 0 to 255
# so the possible negative number will be truncated
imgLaplacian = cv2.filter2D(src, cv2.CV_32F, kernel) # Use cv2.filter2D instead of cv.filter2D
sharp = np.float32(src)
imgResult = sharp - imgLaplacian
# convert back to 8bits gray scale
imgResult = np.clip(imgResult, 0, 255)
imgResult = imgResult.astype('uint8')
imgLaplacian = np.clip(imgLaplacian, 0, 255)
imgLaplacian = np.uint8(imgLaplacian)
#cv.imshow('Laplace Filtered Image', imgLaplacian)
cv2_imshow(imgResult) # Use cv2_imshow instead of cv2.imshow, pass only the image
bw = cv2.cvtColor(imgResult, cv2.COLOR_BGR2GRAY) # Use cv2.cvtColor instead of cv.cvtColor
_, bw = cv2.threshold(bw, 40, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) # Use cv2.threshold instead of cv.threshold
cv2_imshow(bw) # Use cv2_imshow instead of cv2.imshow, pass only the image
dist = cv2.distanceTransform(bw, cv2.DIST_L2, 3) # Use cv2.distanceTransform instead of cv.distanceTransform
# Normalize the distance image for range = {0.0, 1.0}
# so we can visualize and threshold it
cv2.normalize(dist, dist, 0, 1.0, cv2.NORM_MINMAX) # Use cv2.normalize instead of cv.normalize
cv2_imshow(dist) # Use cv2_imshow instead of cv2.imshow, pass only the image
_, dist = cv2.threshold(dist, 0.4, 1.0, cv2.THRESH_BINARY) # Use cv2.threshold instead of cv.threshold
# Dilate a bit the dist image
kernel1 = np.ones((3,3), dtype=np.uint8)
dist = cv2.dilate(dist, kernel1) # Use cv2.dilate instead of cv.dilate
cv2_imshow(dist) # Use cv2_imshow instead of cv2.imshow, pass only the image
dist_8u = dist.astype('uint8')
# Find total markers
contours, _ = cv2.findContours(dist_8u, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Use cv2.findContours instead of cv.findContours
# Create the marker image for the watershed algorithm
markers = np.zeros(dist.shape, dtype=np.int32)
# Draw the foreground markers
for i in range(len(contours)):
    cv2.drawContours(markers, contours, i, (i+1), -1)


# Draw the background marker
cv2.circle(markers, (5,5), 3, (255,255,255), -1) # Use cv2.circle instead of cv.circle
markers_8u = (markers * 10).astype('uint8')
cv2_imshow(markers_8u) # Use cv2_imshow instead of cv2.imshow, pass only the image
cv2.watershed(imgResult, markers) # Use cv2.watershed instead of cv.watershed
#mark = np.zeros(markers.shape, dtype=np.uint8)
mark = markers.astype('uint8')
mark = cv2.bitwise_not(mark) # Use cv2.bitwise_not instead of cv.bitwise_not
# uncomment this if you want to see how the mark
# image looks like at that point
#cv.imshow('Markers_v2', mark)
# Generate random colors
rng = np.random.default_rng()
colors = []
for contour in contours:
    colors.append(tuple(rng.integers(0, 256, size=3)))
# Create the result image
dst = np.zeros((markers.shape[0], markers.shape[1], 3), dtype=np.uint8)
# Fill labeled objects with random colors
for i in range(markers.shape[0]):
    for j in range(markers.shape[1]):
        index = markers[i,j]
        if index > 0 and index <= len(contours):
            dst[i,j,:] = colors[index-1]
# Visualize the final image
cv2_imshow(dst) # Use cv2_imshow instead of cv2.imshow, pass only the image
cv2.waitKey() # Use cv2.waitKey instead of cv.waitKey

"""**Function returning the coin value.**
This is the hard-coded aspect of the processing, where the individual coin types will be classified using their bounding boxes to get their size along with using their saturation levels.
"""

#input: ROI coords (top left, width, height), blob area, image number
#output: coin value (-1 if unknown), mean Sat at centre, mean sat on sides
#accesses Saturation image as well
def classify(x,y,w,h,area,img_idx):
  size = (w+h)/2
  #check mean Saturation in central region
  im = img_HSV[img_idx][1] #Sat component
  sub_img = im[y+h//3:y+2*h//3, x+w//3:x+2*w//3]
  mcenter = cv2.mean(sub_img)
  meanSatcenter = mcenter[0]
  #check mean Saturation in 4 side regions
  sub_img = im[y+h//3:y+2*h//3, x+5:x+w//5] #left
  mside = cv2.mean(sub_img)
  meanSatside = mside[0]
  sub_img = im[y+4*h//5:y+h-5, x+w//3:x+2*w//3] #down
  mside = cv2.mean(sub_img)
  meanSatside = meanSatside + mside[0]
  sub_img = im[y+h//3:y+2*h//3, x+4*w//5:x+w-5] #right
  mside = cv2.mean(sub_img)
  meanSatside = meanSatside + mside[0]
  sub_img = im[y+5:y+h//5, x+w//3:x+2*w//3] #top
  mside = cv2.mean(sub_img)
  meanSatside = meanSatside + mside[0]
  meanSatside = meanSatside // 4
  ###### Classify using sizes and mean Saturation #####
  if size < 80 or size > 160:  #too small or too large
    return (-1, 0, 0)
 #not a coin
  if size < 96: #it's a 5p
      return (0.05, meanSatcenter, meanSatside)
  if size < 108: #it's a 1p
    if meanSatcenter < 100: #not coloured, 5p
      return (0.05, meanSatcenter, meanSatside)
    else: #1p
      return (0.01, meanSatcenter, meanSatside)

  # Complete classification for remaining coins
  if size < 120:  # Medium sized coins - could be 10p or 2p
    if meanSatcenter < 100:  # Lower saturation (silver)
      return (0.10, meanSatcenter, meanSatside)  # 10p
    else:  # Higher saturation (copper)
      return (0.02, meanSatcenter, meanSatside)  # 2p

  if size < 135:  # Larger coins - could be 20p or 50p
    if meanSatcenter < 100:  # Silver coins
      # Could differentiate 20p vs 50p by shape or other features
      # Assuming 20p has slightly lower saturation than 50p
      if meanSatcenter < 75:
        return (0.20, meanSatcenter, meanSatside)  # 20p
      else:
        return (0.50, meanSatcenter, meanSatside)  # 50p

  # Largest coins - £1 or £2
  if meanSatcenter > 120 and meanSatside < 80:  # Bi-metallic characteristics of £2
    return (2.00, meanSatcenter, meanSatside)
  else:  # Likely £1
    return (1.00, meanSatcenter, meanSatside)

  return (-1, 0, 0)  # Unknown coin if none of the above conditions match

# Add after your existing imports
import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

# Function to detect coins using Hough Circle Transform
def detect_coins_hough(image_path, min_radius=40, max_radius=80):
    # Load the image
    img = cv2.imread(image_path)

    # Create a copy for drawing circles
    output = img.copy()

    # Convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Apply GaussianBlur to reduce noise and improve circle detection
    blurred = cv2.GaussianBlur(gray, (9, 9), 2)

    # Apply the Hough Circle Transform
    circles = cv2.HoughCircles(
        blurred,
        cv2.HOUGH_GRADIENT,
        dp=1,           # Resolution accumulator ratio
        minDist=50,     # Minimum distance between circle centers
        param1=100,     # Upper threshold for Canny edge detector
        param2=30,      # Threshold for center detection
        minRadius=min_radius,
        maxRadius=max_radius
    )

    # Create a mask to show the detected coins
    mask = np.zeros_like(gray)

    coin_data = []

    # If circles are found
    if circles is not None:
        # Convert the (x, y, r) coordinates and radius to integers
        circles = np.round(circles[0, :]).astype("int")

        # Loop over each circle found
        for (x, y, r) in circles:
            # Draw the circle on the output image
            cv2.circle(output, (x, y), r, (0, 255, 0), 4)

            # Draw a small circle at the center for visualization
            cv2.circle(output, (x, y), 3, (0, 0, 255), -1)

            # Draw the circle on the mask
            cv2.circle(mask, (x, y), r, 255, -1)

            # Store the coin data (center coordinates and radius)
            coin_data.append((x, y, r))

    return output, mask, coin_data

# Function to integrate Hough Circle detection with your existing classify function
def process_with_hough(img_idx, filename, img_HSV):
    # Load the image
    src = cv2.imread(filename)

    # Apply Hough Circle Transform
    output, mask, coin_data = detect_coins_hough(filename)

    # Get RGB to draw on
    imgRGB = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)

    # Total value of coins
    TotalValue = 0

    # Save results to CSV
    fname = 'result_hough_'+filename+'.csv'
    fp = open(fname, 'w')
    fp.write('x,y,radius,SatCent,SatSides,Value\n')

    # Process each detected coin
    for i, (x, y, r) in enumerate(coin_data):
        # Convert circle to bounding rectangle for classification
        x1 = x - r
        y1 = y - r
        w = 2 * r
        h = 2 * r
        area = np.pi * r * r  # Circle area

        print(f'Coin {i+1}: Center at ({x}, {y}), Radius {r}')

        # Classify the coin
        (value, SatC, SatSide) = classify(x1, y1, w, h, area, img_idx)

        if value == -1:
            print('Unknown value!')
        else:
            # Annotate the coin value
            cv2.putText(imgRGB, str(value), (int(x), int(y)),
                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 0), 6)
            print('Value=' + str(value))
            TotalValue = TotalValue + value

            # Save result to CSV file
            fp.write(f"{x},{y},{r},{int(SatC)},{int(SatSide)},{value}\n")

    fp.close()

    # Display results
    fig = plt.figure(figsize=(18, 6), dpi=80)
    ax = fig.add_subplot(131, aspect='auto')
    ax.imshow(cv2.cvtColor(src, cv2.COLOR_BGR2RGB))
    ax.set_title('Original Image')

    ax = fig.add_subplot(132, aspect='auto')
    ax.imshow(mask, cmap='gray')
    ax.set_title('Coin Mask')

    ax = fig.add_subplot(133, aspect='auto')
    ax.imshow(imgRGB)
    ax.set_title('Detected Coins')

    plt.tight_layout()
    plt.show()

    print('TOTAL: £' + str(TotalValue))
    return imgRGB, TotalValue, coin_data

# Implementation that combines both methods
def enhanced_coin_detection(img_idx, filename, img_HSV):
    """
    Enhance coin detection by combining blob detection and Hough circle transform
    """
    # Load the image
    src = cv2.imread(filename)

    # Step 1: Apply your existing processing method
    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)
    imgLaplacian = cv2.filter2D(src, cv2.CV_32F, kernel)
    sharp = np.float32(src)
    imgResult = sharp - imgLaplacian
    imgResult = np.clip(imgResult, 0, 255)
    imgResult = imgResult.astype('uint8')
    bw = cv2.cvtColor(imgResult, cv2.COLOR_BGR2GRAY)
    _, bw = cv2.threshold(bw, 40, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)

    # Step 2: Apply Hough Circle Transform
    # Convert to grayscale
    gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
    # Apply GaussianBlur to reduce noise
    blurred = cv2.GaussianBlur(gray, (9, 9), 2)
    # Apply the Hough Circle Transform
    circles = cv2.HoughCircles(
        blurred,
        cv2.HOUGH_GRADIENT,
        dp=1,
        minDist=50,
        param1=100,
        param2=30,
        minRadius=40,
        maxRadius=80
    )

    # Step 3: Combine both methods
    # Get connected components from binary image
    (numLabels, labels_img, stats, centroids) = cv2.connectedComponentsWithStats(bw)

    # Create output image
    imgRGB = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)

    # Store results
    TotalValue = 0
    coin_info = []

    # Save results to CSV
    fname = 'result_enhanced_'+filename+'.csv'
    fp = open(fname, 'w')
    fp.write('x,y,width,height,radius,SatCent,SatSides,Value,Method\n')

    # Process connected components (your original method)
    for i in range(1, numLabels):
        x1 = stats[i, cv2.CC_STAT_LEFT]
        y1 = stats[i, cv2.CC_STAT_TOP]
        w = stats[i, cv2.CC_STAT_WIDTH]
        h = stats[i, cv2.CC_STAT_HEIGHT]
        area = stats[i, cv2.CC_STAT_AREA]
        (cX, cY) = centroids[i]

        # Filter shapes that are likely to be coins
        if abs(w-h) <= 10 and (w+h)/2 >= 80:
            # Classify the potential coin
            (value, SatC, SatSide) = classify(x1, y1, w, h, area, img_idx)

            if value != -1:
                # Save coin info
                coin_info.append({
                    'x': x1, 'y': y1, 'w': w, 'h': h,
                    'value': value, 'method': 'blob',
                    'center': (cX, cY), 'satC': SatC, 'satS': SatSide
                })

    # Process Hough circles
    if circles is not None:
        circles = np.round(circles[0, :]).astype("int")

        for (x, y, r) in circles:
            # Convert circle to bounding rectangle for classification
            x1 = x - r
            y1 = y - r
            w = 2 * r
            h = 2 * r
            area = np.pi * r * r

            # Classify using your existing function
            (value, SatC, SatSide) = classify(x1, y1, w, h, area, img_idx)

            if value != -1:
                # Save coin info
                coin_info.append({
                    'x': x1, 'y': y1, 'w': w, 'h': h, 'r': r,
                    'value': value, 'method': 'hough',
                    'center': (x, y), 'satC': SatC, 'satS': SatSide
                })

    # Remove duplicates by checking for overlapping centers
    unique_coins = []
    centers_used = []

    for coin in coin_info:
        center = coin['center']
        is_duplicate = False

        for used_center in centers_used:
            # Calculate distance between centers
            dist = np.sqrt((center[0] - used_center[0])**2 + (center[1] - used_center[1])**2)
            if dist < 30:  # If centers are close, consider as duplicate
                is_duplicate = True
                break

        if not is_duplicate:
            centers_used.append(center)
            unique_coins.append(coin)

            # Draw rectangle or circle based on detection method
            if coin['method'] == 'blob':
                cv2.rectangle(imgRGB, (int(coin['x']), int(coin['y'])),
                             (int(coin['x'] + coin['w']), int(coin['y'] + coin['h'])),
                             (0, 255, 0), 3)
            else:
                cv2.circle(imgRGB, (int(center[0]), int(center[1])),
                          int(coin['r']), (0, 255, 0), 3)

            # Annotate value
            cv2.putText(imgRGB, str(coin['value']),
                       (int(center[0]), int(center[1])),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 3)

            # Add to total and save to CSV
            TotalValue += coin['value']
            fp.write(f"{coin['x']},{coin['y']},{coin['w']},{coin['h']},{coin.get('r', 0)}," +
                    f"{int(coin['satC'])},{int(coin['satS'])},{coin['value']},{coin['method']}\n")

    fp.close()

    # Display results
    fig = plt.figure(figsize=(18, 6), dpi=80)
    ax = fig.add_subplot(131, aspect='auto')
    ax.imshow(cv2.cvtColor(src, cv2.COLOR_BGR2RGB))
    ax.set_title('Original Image')

    ax = fig.add_subplot(132, aspect='auto')
    ax.imshow(labels_img, cmap='flag')
    ax.set_title('Connected Components')

    ax = fig.add_subplot(133, aspect='auto')
    ax.imshow(imgRGB)
    ax.set_title('Enhanced Detection')

    plt.tight_layout()
    plt.show()

    print('TOTAL: £' + str(TotalValue))
    return imgRGB, TotalValue, unique_coins

# To call this function for each image:
# Replace your image processing loop with:
for image_to_use in range(len(img_HSV)):
    print(f"Processing image {image_to_use+1}: {filename[image_to_use]}")
    result_img, total_value, coins = enhanced_coin_detection(image_to_use, filename[image_to_use], img_HSV)
    print(f"Detected {len(coins)} coins with total value: £{total_value}")

"""**Labelling and individual region analysis.**
This section of the code deals with processing the images to identify which coins are of a specific denomination and to in the end total up their combined value within the image. Notably this section works in a loop as the google colab import files function allows for multiple file uploads in one go, so this loop allows for the processing of each individual image to test the whole dataset in one run of the program.

"""

"""
image_to_use = 0 #Processing only one this image element so far
fname = 'result_'+filename[image_to_use]+'.csv'
fp = open(fname, 'w')
fp.write(' x1, y1,w,h,SatCent,SatSides,Value\n')
TotalValue = 0
#get RGB again to clean up drawings if repeated execution
imgRGB=cv2.cvtColor(cv2.imread(filename[image_to_use]), cv2.COLOR_BGR2RGB)
#get binary image to process for blob extraction
# Assuming 'bw' from the previous cell contains your binary image
bin_img = [bw]  # Create bin_img and assign bw to it
binary = bin_img[image_to_use]
#use connectedComponentsWithStats to retrieve blobs and stats
(numLabels, labels_img, stats, centroids) = cv2.connectedComponentsWithStats(binary)
print('Found ' + str(numLabels - 1) + ' blobs')
for i in range(1,numLabels):
   draw_ROI = 0
   x1 = stats[i, cv2.CC_STAT_LEFT]
   y1 = stats[i, cv2.CC_STAT_TOP]
   w = stats[i, cv2.CC_STAT_WIDTH]
   h = stats[i, cv2.CC_STAT_HEIGHT]
   area = stats[i, cv2.CC_STAT_AREA]
   (cX, cY) = centroids[i]
   if abs(w-h)>10: #too unsquare
     print('Blob '+str(i) +'too unsquare!')
   else:
     size = (h + w)/2
     if size < 80:
       print('Blob '+str(i) +'too small!')
     else:
       print('Blob '+ str(i) +' IS COIN')
       draw_ROI = 1
       (value, SatC, SatSide) = classify(x1,y1,w,h,area,image_to_use) # Removed coin_params
       if value == -1 :
          print('Unknown value!')
       else :
          cv2.putText(imgRGB, str(value), (int(x1),int(y1+h/2)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,0),6)
          print('Value=' + str(value))
          TotalValue = TotalValue + value
          #save result to text file
          fp.write(str(x1)+','+str(y1)+','+str(w)+','+str(h)+','+str(int(SatC))+','+str(int(SatSide))+','+str(value)+'\n')
     if draw_ROI:
       cv2.rectangle(imgRGB,(x1,y1),(x1+w,y1+h),(0,255,0),3)
fp.close()
#plot results
fig = plt.figure(figsize=(12, 6), dpi=80)
ax = fig.add_subplot(121, aspect='auto')
ax.imshow(labels_img, cmap='flag', vmin=0, vmax=255)
ax.set_title(filename[image_to_use] + '  Labels')
ax = fig.add_subplot(122, aspect='auto')
ax.imshow(imgRGB)
ax.set_title(filename[image_to_use] +'  ROIs')
print('TOTAL: £' +str(TotalValue))
"""

# Replace the current single-image processing code with this loop
for image_to_use in range(len(img_HSV)):  # Loop through all uploaded images
    fname = 'result_'+filename[image_to_use]+'.csv'
    fp = open(fname, 'w')
    fp.write(' x1, y1,w,h,SatCent,SatSides,Value\n')
    TotalValue = 0

    # Get RGB again to clean up drawings if repeated execution
    imgRGB = cv2.cvtColor(cv2.imread(filename[image_to_use]), cv2.COLOR_BGR2RGB)

    # Process this specific image to get binary image
    # You need to repeat the binary image creation steps for each image
    src = cv2.imread(filename[image_to_use])
    # Apply the same processing steps as before to create binary image
    kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], dtype=np.float32)
    imgLaplacian = cv2.filter2D(src, cv2.CV_32F, kernel)
    sharp = np.float32(src)
    imgResult = sharp - imgLaplacian
    imgResult = np.clip(imgResult, 0, 255)
    imgResult = imgResult.astype('uint8')
    bw = cv2.cvtColor(imgResult, cv2.COLOR_BGR2GRAY)
    _, bw = cv2.threshold(bw, 40, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)

    # Use bw as your binary image for this iteration
    binary = bw

    # Use connectedComponentsWithStats to retrieve blobs and stats
    (numLabels, labels_img, stats, centroids) = cv2.connectedComponentsWithStats(binary)
    print(f'Image {image_to_use+1}: {filename[image_to_use]}')
    print('Found ' + str(numLabels - 1) + ' blobs')

    for i in range(1, numLabels):
        draw_ROI = 0
        x1 = stats[i, cv2.CC_STAT_LEFT]
        y1 = stats[i, cv2.CC_STAT_TOP]
        w = stats[i, cv2.CC_STAT_WIDTH]
        h = stats[i, cv2.CC_STAT_HEIGHT]
        area = stats[i, cv2.CC_STAT_AREA]
        (cX, cY) = centroids[i]

        if abs(w-h) > 10:  # too unsquare
            print('Blob '+str(i) +' too unsquare!')
        else:
            size = (h + w)/2
            if size < 80:
                print('Blob '+str(i) +' too small!')
            else:
                print('Blob '+ str(i) +' IS COIN')
                draw_ROI = 1
                (value, SatC, SatSide) = classify(x1, y1, w, h, area, image_to_use)
                if value == -1:
                    print('Unknown value!')
                else:
                    cv2.putText(imgRGB, str(value), (int(x1), int(y1+h/2)),
                                cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 0), 6)
                    print('Value=' + str(value))
                    TotalValue = TotalValue + value
                    # save result to text file
                    fp.write(str(x1)+','+str(y1)+','+str(w)+','+str(h)+','+
                             str(int(SatC))+','+str(int(SatSide))+','+str(value)+'\n')
            if draw_ROI:
                cv2.rectangle(imgRGB, (x1, y1), (x1+w, y1+h), (0, 255, 0), 3)

    fp.close()

    # Plot results for this image
    fig = plt.figure(figsize=(12, 6), dpi=80)
    ax = fig.add_subplot(121, aspect='auto')
    ax.imshow(labels_img, cmap='flag', vmin=0, vmax=255)
    ax.set_title(filename[image_to_use] + '  Labels')
    ax = fig.add_subplot(122, aspect='auto')
    ax.imshow(imgRGB)
    ax.set_title(filename[image_to_use] + '  ROIs')
    print('TOTAL: £' + str(TotalValue))